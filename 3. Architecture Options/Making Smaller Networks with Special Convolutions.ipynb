{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Smaller Networks With Special Convolutions\n",
    "\n",
    "In this notebook we are going to try and make a usual CNN smaller with the use of Depth-separable convolutions and spatially separable convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the environment\n",
    "\n",
    "Since I'll be running this at our servers, this code will set up tensorflow to use only one GPU and not fill up the VRAM memory. We'll also be importing tensorflow here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def setup_gpu(gpu_ids):\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            sel_gpus = [gpus[g] for g in gpu_ids]\n",
    "            tf.config.set_visible_devices(sel_gpus, 'GPU')\n",
    "            for g in sel_gpus:\n",
    "                tf.config.experimental.set_memory_growth(g, True)\n",
    "        except RuntimeError as e:\n",
    "            # visible devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "            \n",
    "setup_gpu([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST\n",
    "\n",
    "In the interest of time, we are going with a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0, dtype('uint8'), (60000, 28, 28))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(), x_train.min(), x_train.dtype, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "x_train, x_test = x_train[..., None], x_test[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0, dtype('uint8'), (60000,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max(), y_train.min(), y_train.dtype, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = tf.one_hot(y_train, 10), tf.one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mnist_set = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train), \n",
    "                                   tf.data.Dataset.from_tensor_slices(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mnist_test = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_test), \n",
    "                                   tf.data.Dataset.from_tensor_slices(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Big Network\n",
    "\n",
    "We make a usual network and train it on f mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 105,866\n",
      "Trainable params: 105,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_input = tf.keras.Input([28, 28, 1])\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x_input)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_a = tf.keras.Model(x_input, x)\n",
    "model_a.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We make an optimiser and model trainer \n",
    "\n",
    "We'll go and make this model trainer flexible for the next models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_trainer(model, opt):\n",
    "    @tf.function\n",
    "    def trainer(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x)\n",
    "            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, y_pred))\n",
    "            \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        return loss\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.optimizers.Adam()\n",
    "model_a_trainer = make_model_trainer(model_a, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37500: Loss: 0.11489166319370276184\r"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x, y in f_mnist_set.shuffle(60000).batch(32).repeat(50):\n",
    "    loss = model_a_trainer(x, y)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 200 == 0:\n",
    "        print(f\"{counter}: Loss: {loss}\", end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And we see if it worked\n",
    "\n",
    "By maaking an accuracy function we can reuse later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "def acc(model):\n",
    "    y_pred = model.predict(x_test, batch_size=32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.argmax(y_test) == tf.argmax(y_pred), tf.float32))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "acc(model_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially Separabe Convolutions\n",
    "\n",
    "To the rescue! We want to make this model faster and with less parameters so we'll take each conv layer and break it into two smaller ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 28, 28, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 64)        12352     \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 14, 14, 64)        12352     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 7, 7, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 64)          12352     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 93,386\n",
      "Trainable params: 93,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_input = tf.keras.Input([28, 28, 1])\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=(1, 3), padding='same', activation='relu')(x_input)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=(3, 1), padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=(1, 3), padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=(3, 1), padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=(1, 3), padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=(3, 1), padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_b = tf.keras.Model(x_input, x)\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.optimizers.Adam()\n",
    "model_b_trainer = make_model_trainer(model_b, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93750: Loss: 0.01288359332829713825\r"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x, y in f_mnist_set.shuffle(60000).batch(32).repeat(50):\n",
    "    loss = model_b_trainer(x, y)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 200 == 0:\n",
    "        print(f\"{counter}: Loss: {loss}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "acc(model_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally, Depthwise-Separable Convolutions\n",
    "\n",
    "Where we'll have to use a special kind of layer that does uses a single filter and does not sum the resulting maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_18 (Depthwi (None, 28, 28, 1)         10        \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 28, 28, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_19 (Depthwi (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 14, 14, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_20 (Depthwi (None, 7, 7, 64)          640       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 64)          4160      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 41,108\n",
      "Trainable params: 41,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_input = tf.keras.Input([28, 28, 1])\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same')(x_input)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=1, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=1, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
    "x = tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size=1, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_c = tf.keras.Model(x_input, x)\n",
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.optimizers.Adam()\n",
    "model_c_trainer = make_model_trainer(model_c, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93700: Loss: 0.0830423161387443545\r"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x, y in f_mnist_set.shuffle(60000).batch(32).repeat(50):\n",
    "    loss = model_c_trainer(x, y)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 500 == 0:\n",
    "        print(f\"{counter}: Loss: {loss}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "acc(model_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
